{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8024b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import copy\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "import cv2 # import after setting OPENCV_IO_MAX_IMAGE_PIXELS\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d4d823cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_simple(a, b):\n",
    "    \n",
    "    #Calculates the angle of a straight line (with respect to the horizon) between points a and b:\n",
    "    return math.degrees(math.atan2(a[1] - b[1], a[0] - b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "bd63019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_simple_vert(a, b):\n",
    "    \n",
    "    #Calculates the angle of a straight line (with respect to the horizon) between points a and b:\n",
    "    return math.degrees(math.atan2(b[0] - a[0], a[1] - b[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "5a239569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_averaged(alignment_pts):\n",
    "    \n",
    "    #For a set of points a, b, c, d in alignment_pts, calculated the angle of each straight line edge of the quadrilateral (ie. get the angle of A-B, A-C, B-D, C-D) and average them:\n",
    "    angle1 = get_angle_simple(alignment_pts[1], alignment_pts[0])\n",
    "    angle2 = get_angle_simple(alignment_pts[3], alignment_pts[2])\n",
    "    angle3 = get_angle_simple_vert(alignment_pts[2], alignment_pts[0])\n",
    "    angle4 = get_angle_simple_vert(alignment_pts[3], alignment_pts[1])\n",
    "    \n",
    "    angle = (angle1 + angle2 + angle3 + angle4)/4\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "043fa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_rotated(img, h_old, w_old, angle):\n",
    "    \n",
    "    #Rotates an image by a given angle... then crops the image to remove the rotational defects:\n",
    "    a = abs(math.radians(angle))\n",
    "    sin_a = abs(math.sin(a))\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    dh, dw = h_old * sin_a, w_old * sin_a\n",
    "    hc, wc = h - 2 * dh, w - 2 * dw\n",
    "    \n",
    "    return img[int((h-hc)/2):int((h+hc)/2), int((w-wc)/2):int((w+wc)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f77bf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(pts, img, theta, ox, oy):\n",
    "    \n",
    "    #Makes labels in the image for die offsets and rotation:\n",
    "    data_pts = np.empty((len(pts), 2), dtype=np.float64)\n",
    "    \n",
    "    for i in range(data_pts.shape[0]):\n",
    "        \n",
    "        data_pts[i, 0] = pts[i, 0, 0]\n",
    "        data_pts[i, 1] = pts[i, 0, 1]\n",
    "        mean = np.empty((0))\n",
    "        mean, eigenvectors, eigenvalues = cv2.PCACompute2(data_pts, mean)\n",
    "        cntr = (int(mean[0, 0]), int(mean[0, 1]))\n",
    "        label_rotation = \" Rotation: \" + (\"%.4f\" % theta) + \" degrees\"\n",
    "        label_offset = \" Offset: \" + (\"(%.4f, %.4f)\" % (ox, oy) + \" um\")\n",
    "        textbox = cv2.rectangle(img, (cntr[0], cntr[1] - 25), (cntr[0] + 300, cntr[1] + 45), (255, 255, 255), -1)\n",
    "        cv2.putText(img, label_rotation, (cntr[0], cntr[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(img, label_offset, (cntr[0], cntr[1] + 35), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "383c4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_alignment_marker_list(alignment_pts):\n",
    "    \n",
    "    #Orders the list of global alignment marker positions such that it is in the order LL, LR, UL, UR:\n",
    "    new_list = alignment_pts.copy()\n",
    "    sum = np.zeros((np.shape(alignment_pts)[0]), dtype='int')\n",
    "    h = 0\n",
    "    \n",
    "    while h < 2:\n",
    "        \n",
    "        i = 2*h\n",
    "        j = i + 1\n",
    "        sum[i] = new_list[i][0] + new_list[i][1]\n",
    "        sum[j] = new_list[j][0] + new_list[j][1]\n",
    "        \n",
    "        if sum[j] < sum[i]:\n",
    "            \n",
    "            new_list[i] = alignment_pts[j]\n",
    "            new_list[j] = alignment_pts[i]\n",
    "        \n",
    "        h = h + 1\n",
    "    \n",
    "    alignment_pts = new_list.copy()\n",
    "    \n",
    "    return alignment_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "50a2b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scale_using_alignment_markers(alignment_pts, alignment_mark_dist):\n",
    "    \n",
    "    #Image scale is calculed using the global alignment marker coordinates and given marker to marker distance:\n",
    "    d01 = np.absolute(alignment_pts[0] - alignment_pts[1])\n",
    "    d02 = np.absolute(alignment_pts[0] - alignment_pts[2])\n",
    "    d13 = np.absolute(alignment_pts[1] - alignment_pts[3])\n",
    "    d23 = np.absolute(alignment_pts[2] - alignment_pts[3])\n",
    "    \n",
    "    dist01 = np.linalg.norm(d01)\n",
    "    dist02 = np.linalg.norm(d02)\n",
    "    dist13 = np.linalg.norm(d13)\n",
    "    dist23 = np.linalg.norm(d23)\n",
    "    \n",
    "    max_vertical_dist = max(d01[0], d02[0], d13[0], d23[0])\n",
    "    max_horizontal_dist = max(d01[1], d02[1], d13[1], d23[1])\n",
    "    rescale_amount = max_horizontal_dist / max_vertical_dist\n",
    "    avg_pixel_dist = (dist01 + dist02 + dist13 + dist23) / 4\n",
    "    pixel_um_scale = alignment_mark_dist / avg_pixel_dist\n",
    "    \n",
    "    print('Pixel to um scale (w.r.t. alignment markers) [um/pixel]:', pixel_um_scale)\n",
    "    \n",
    "    return pixel_um_scale, rescale_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "94eacc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_template(result, img, template, template_name, threshold):\n",
    "    \n",
    "    #Match template based on threshold value:\n",
    "    w, h = template.shape[::-1]\n",
    "    \n",
    "    #Using matching operation TM_CCORR_NORMED (23/01/30):\n",
    "    res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    n = np.count_nonzero(res >= threshold)\n",
    "    pts = np.dstack(np.unravel_index(np.argsort(res.ravel()), res.shape))[0]\n",
    "    pts = pts[::-1][:n]\n",
    "    pts[:, [1, 0]] = pts[:, [0, 1]]\n",
    "    \n",
    "    delete = []\n",
    "    \n",
    "    for i in range(len(pts)):\n",
    "        \n",
    "        for j in range(i + 1, len(pts)):\n",
    "            \n",
    "            if np.linalg.norm(pts[i] - pts[j]) <= 15 and j not in delete:\n",
    "                \n",
    "                delete.append(j)\n",
    "                \n",
    "    pts = np.delete(pts, delete, axis=0)\n",
    "    pts = pts[np.lexsort((pts[:, 0], pts[:, 1]))]\n",
    "    \n",
    "    for pt in pts:\n",
    "        \n",
    "        cv2.rectangle(result, (pt[0], pt[1]), (pt[0] + w, pt[1] + h), (0, 0, 255), 8)\n",
    "        \n",
    "    print(\"Detected \" + template_name + \" markers:\", len(pts))\n",
    "    \n",
    "    return pts, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "67970d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_dies(contours, alignment_pts, min_die_area=20000, max_die_area=100000):\n",
    "    \n",
    "    #Identify dies with thresholding/contouring based on a minimum and maximum die area:\n",
    "    nontrivial_contours = []\n",
    "    nontrivial_offsets = []\n",
    "    \n",
    "    for i, c in enumerate(contours):\n",
    "        \n",
    "        area = cv2.contourArea(c)\n",
    "        #print(area)\n",
    "        \n",
    "        if area < min_die_area or area > max_die_area:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        \n",
    "        is_alignment_mark = False\n",
    "        \n",
    "        for alignment_pt in alignment_pts:\n",
    "            \n",
    "            if math.dist([x, y], alignment_pt) < 300:\n",
    "                \n",
    "                is_alignment_mark = True\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if is_alignment_mark:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        nontrivial_contours.append(c)\n",
    "        nontrivial_offsets.append([x, y])\n",
    "    \n",
    "        \n",
    "    nontrivial_contours.sort(key=lambda c: (cv2.boundingRect(c)[0], cv2.boundingRect(c)[1]))\n",
    "    nontrivial_offsets.sort(key=lambda o: (o[0], o[1]))\n",
    "    x_coords = [o[0] for o in nontrivial_offsets]\n",
    "    y_coords = [o[1] for o in nontrivial_offsets]\n",
    "\n",
    "    # Use np.lexsort with the tuple of arrays\n",
    "    sorted_indices = np.lexsort((y_coords, x_coords))\n",
    "\n",
    "    # Use sorted indices to sort nontrivial_offsets\n",
    "    sorted_nontrivial_offsets = np.array(nontrivial_offsets)[sorted_indices]\n",
    "\n",
    "    nontrivial_offsets = np.array(nontrivial_offsets)\n",
    "    \n",
    "    return nontrivial_contours, nontrivial_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d10b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_corner_markers(result, w1, h1, w2, h2, template1_pts, template2_pts):\n",
    "    \n",
    "    #Identify the corner marker locations with a die based on template matching and draw box:\n",
    "    T1 = np.array(template1_pts)\n",
    "    T2 = np.array(template2_pts)\n",
    "    c1 = np.array([w1, h1])\n",
    "    c2 = np.array([w2, h2])\n",
    "    \n",
    "    if len(T1) < len(T2):\n",
    "        lengthT = len(T1)\n",
    "    else:\n",
    "        lengthT = len(T2)\n",
    "    \n",
    "    i = 0\n",
    "    while i < lengthT - 1:\n",
    "        box = np.int0([T1[i] + c1, T1[i+1] + c1, T2[i+1] + c2, T2[i] + c2])\n",
    "        #cv2.polylines(result, [box], True, (255, i * 30 % 255, 0), 3)\n",
    "        \n",
    "        #p = [box[0][0], box[0][1] + 100]\n",
    "        #theta = get_angle(box[1], box[0], p)\n",
    "        #theta = 0 - get_angle_simple(box[1], box[0])\n",
    "        #theta = min(abs(theta), 90 - abs(theta))\n",
    "        #cntr = [box[0][0], box[0][1]]\n",
    "        # textbox = cv2.rectangle(result, (cntr[0], cntr[1] - 25), (cntr[0] + 250, cntr[1] + 20), (255, 255, 255), -1)\n",
    "        # label_rotation = \" Rotation: \" + (\"%.4f\" % theta) + \" degrees\"\n",
    "        # cv2.putText(result, label_rotation, (cntr[0], cntr[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        i += 2\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "df0d208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_offset(alignment_pts, die_offsets, ideal_param, image_paths):\n",
    "    # calculates the distance between the UL alignment marker and the UL die contour\n",
    "    result = cv2.imread(image_paths['input'])\n",
    "    print(\"UL ALIGNMENT PT\", alignment_pts[2])\n",
    "    x,y = alignment_pts[0]\n",
    "    cv2.circle(result, (x, y), 10, (0, 92, 255), -1)\n",
    "\n",
    "    dx, dy = die_offsets[0][0], die_offsets[0][1] \n",
    "    cv2.circle(result, (int(dx), int(dy)), 10, (100, 92, 255), -1)\n",
    "    dx \n",
    "    dy \n",
    "    print(dx)\n",
    "    print(dy)\n",
    "    cv2.circle(result, (int(dx), int(dy)), 10, (0, 92, 255), -1)\n",
    "    x_offset = x-dx\n",
    "    y_offset = -(y-dy)\n",
    "    print(\"x offset\", x_offset)\n",
    "    print(\"y offset\", y_offset)\n",
    "    return x_offset, y_offset, result\n",
    "\n",
    "    #find the distance between the alignment+pt and the first die_offset by subtracting x and y coord\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c8508183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_misalignment(result, die_contours, die_offsets, alignment_pts, ideal_param, image_paths):\n",
    "    \n",
    "    \n",
    "    #Identify misalignment of dies with respect to the expected location given a known shift in the assembly during die placement:\n",
    "    # midpoint according to alignment markers and assembly offset\n",
    "    #ideal_param['x_midpoint'] = x_midpoint\n",
    "    #ideal_param['y_midpoint'] = y_midpoint\n",
    "    scale = ideal_param['scale']\n",
    "    ideal_param['x_midpoint'] = np.mean(alignment_pts[:, 0]) + ideal_param['assembly_x_offset'] / scale\n",
    "    ideal_param['y_midpoint'] = np.mean(alignment_pts[:, 1]) - ideal_param['assembly_y_offset'] / scale\n",
    "    x_midpoint = ideal_param['x_midpoint']\n",
    "    y_midpoint = ideal_param['y_midpoint']\n",
    "    num_rows = ideal_param['num_rows']\n",
    "    num_cols = ideal_param['num_cols']\n",
    "    # die width and pitch in pixels\n",
    "    die_width = 1.1*ideal_param['die_width'] / scale\n",
    "    pitch = ideal_param['pitch'] / scale\n",
    "    # ideal top left corner of die layout\n",
    "    dies_layout_vertical_width = (num_rows - 1) * pitch + die_width\n",
    "    dies_layout_horizontal_width = (num_cols - 1) * pitch + die_width\n",
    "    x_start = x_midpoint - dies_layout_vertical_width // 2\n",
    "    y_start = y_midpoint - dies_layout_horizontal_width // 2\n",
    "    ideal_param['x_start'] = x_start\n",
    "    ideal_param['y_start'] = y_start\n",
    "    ideal_pts = np.zeros((num_rows, num_cols, 2))\n",
    "    \n",
    "    for r in range(num_rows):\n",
    "        \n",
    "        for c in range(num_cols):\n",
    "            \n",
    "            ideal_pts[r, c, 0] = x_start + r * pitch\n",
    "            ideal_pts[r, c, 1] = y_start + c * pitch\n",
    "            tl = np.int0([ideal_pts[r, c, 0], ideal_pts[r, c, 1]])\n",
    "            br = np.int0([ideal_pts[r, c, 0] + die_width, ideal_pts[r, c, 1] + die_width])\n",
    "            cv2.rectangle(result, tl, br, (0, 0, 255), 5)\n",
    "    \n",
    "    shifts_relative = {}\n",
    "    shifts_absolute = {}\n",
    "    midpts = np.zeros((num_rows, num_cols, 2))\n",
    "    \n",
    "    for i, contour in enumerate(die_contours):\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(result, [box], 0, (0, 255, 0), 8)\n",
    "        \n",
    "        theta = rect[2]\n",
    "        sign_theta = np.sign(theta)\n",
    "        \n",
    "        if abs(theta) == 0 or abs(theta) == 90:\n",
    "            \n",
    "            theta = 0\n",
    "        \n",
    "        theta = sign_theta * min(abs(theta), 90 - abs(theta))\n",
    "        p = np.array([x, y])\n",
    "        dists = np.sum((ideal_pts - p)**2, axis=-1)\n",
    "        idx = np.unravel_index(np.argmin(dists), dists.shape)\n",
    "        r, c = int(idx[0]), int(idx[1])\n",
    "        midpts[r, c, 0] = x + w / 2\n",
    "        midpts[r, c, 1] = y + h / 2\n",
    "        ox = scale * (x - ideal_pts[r, c, 0])\n",
    "        oy = - scale * (y - ideal_pts[r, c, 1])\n",
    "        ox_absolute = scale * (x - x_start)\n",
    "        oy_absolute = - scale * (y - y_start)\n",
    "        \n",
    "        if r not in shifts_relative:\n",
    "            \n",
    "            shifts_relative[r] = {}\n",
    "            shifts_absolute[r] = {}\n",
    "        \n",
    "        shifts_relative[r][c] = {'x': ox, 'y': oy, 'theta': theta}\n",
    "        shifts_absolute[r][c] = {'x': ox_absolute, 'y': oy_absolute, 'theta': theta}\n",
    "        #make_label(contour, result, theta, ox, oy)\n",
    "    \n",
    "    ideal_param['midpts'] = midpts\n",
    "   \n",
    "    \n",
    "    for i, c in enumerate(alignment_pts):\n",
    "        \n",
    "        ox = scale * (c[0] - x_start)\n",
    "        oy = - scale * (c[1] - y_start)\n",
    "        shifts_absolute['a' + str(i)] = {'x': ox, 'y': oy}\n",
    "    \n",
    "    # TODO: rewrite / confirm !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \n",
    "    with open(image_paths['scan_dir'] + '/shifts_relative.json', 'w') as f:\n",
    "        json.dump(shifts_relative, f)\n",
    "    with open(image_paths['scan_dir'] + '/shifts_absolute.json', 'w') as f:\n",
    "        json.dump(shifts_absolute, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "4ff93d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_misalignment_with_corner_markers(template1_pts, template2_pts, alignment_pts, ideal_param, image_paths):\n",
    "    \n",
    "    #Identify die misalignment with corner markers and export to CSV:\n",
    "    scale = ideal_param['scale']\n",
    "    midpts = ideal_param['midpts']#expected midpt of unshifted die, 2d matrix that is 5x5\n",
    "    x_midpoint = ideal_param['x_midpoint']\n",
    "    y_midpoint = ideal_param['y_midpoint']\n",
    "    \n",
    "    max_dist_to_midpt = ((ideal_param['die_width']/2)**2 + (ideal_param['die_height']/2)**2)/(scale**2)\n",
    "    oc = ideal_param['oc']\n",
    "    \n",
    "    dies_to_markers = {}\n",
    "    shifts = {}\n",
    "    shifts_csv = {}\n",
    "    \n",
    "    for p in template1_pts:\n",
    "        \n",
    "        dists = np.sum((midpts - p)**2, axis=-1)\n",
    "        \n",
    "        \n",
    "        # find the index (row, column) of the closest corresponding die\n",
    "        idx = np.unravel_index(np.argmin(dists), dists.shape)#converts index back to 2d shape of dists, which is formed by shape of midpts\n",
    "        \n",
    "        if dists[idx] > max_dist_to_midpt:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        r, c = int(idx[0]), int(idx[1])\n",
    "        print(f\"dies to markers: {r},{c}\")\n",
    "        \n",
    "        # account for defects\n",
    "        if r not in dies_to_markers:\n",
    "            \n",
    "            dies_to_markers[r] = {}\n",
    "        \n",
    "        if c not in dies_to_markers[r]:\n",
    "            \n",
    "            dies_to_markers[r][c] = []\n",
    "        \n",
    "        dies_to_markers[r][c].append(p)#NEED TO ADD .TOLIST AFTER TESTING\n",
    "        \n",
    "        if len(dies_to_markers[r][c]) == 2:\n",
    "            \n",
    "            markers = dies_to_markers[r][c]\n",
    "            markers.sort(key=lambda m: (m[0], m[1]))\n",
    "            theta = get_angle_simple(markers[1], markers[0])\n",
    "            sign_theta = - np.sign(theta)\n",
    "            theta = sign_theta * min(abs(theta), 90 - abs(theta))\n",
    "            \n",
    "            \n",
    "            if r not in shifts:\n",
    "                \n",
    "                shifts[r] = {}\n",
    "            \n",
    "            if c not in shifts[r]:\n",
    "                print(f\"shifts csv: {r},{c}\")\n",
    "                shifts[r][c] = {}\n",
    "            \n",
    "            shifts[r][c]['theta'] = theta\n",
    "            shifts_csv[str(r) + ', ' + str(c)] = {'theta': theta}\n",
    "        \n",
    "    for p in template2_pts:\n",
    "        \n",
    "        dists = np.sum((midpts - p)**2, axis=-1)\n",
    "        idx = np.unravel_index(np.argmin(dists), dists.shape)\n",
    "        \n",
    "        if dists[idx] > max_dist_to_midpt:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        r, c = int(idx[0]), int(idx[1])\n",
    "        \n",
    "        if r not in dies_to_markers:\n",
    "            \n",
    "            dies_to_markers[r] = {}\n",
    "        \n",
    "        if c not in dies_to_markers[r]:\n",
    "            \n",
    "            dies_to_markers[r][c] = []\n",
    "        \n",
    "        dies_to_markers[r][c].append(p)#NEED TO ADD .TOLIST AFTER TESTING\n",
    "    \n",
    "    for r in shifts:\n",
    "        \n",
    "        for c in shifts[r]:\n",
    "            \n",
    "            markers = dies_to_markers[r][c]\n",
    "            # skip defects (TODO: fixable?)\n",
    "            \n",
    "            if len(markers) < 4:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            # compute average of four corner markers\n",
    "            die_center = np.mean(markers, axis=0) # + oc\n",
    "            ox = scale * (die_center[0] - x_midpoint)\n",
    "            oy = - scale * (die_center[1] - y_midpoint)\n",
    "            shifts[r][c]['x'] = ox\n",
    "            shifts[r][c]['y'] = oy\n",
    "            shifts_csv[str(r) + ', ' + str(c)]['x'] = ox\n",
    "            shifts_csv[str(r) + ', ' + str(c)]['y'] = oy\n",
    "    \n",
    "    for i, c in enumerate(alignment_pts):\n",
    "        \n",
    "        ox = scale * (c[0] - x_midpoint)\n",
    "        oy = - scale * (c[1] - y_midpoint)\n",
    "        shifts['alignment ' + str(i)] = {'x': ox, 'y': oy, 'theta': 0}\n",
    "        shifts_csv['alignment ' + str(i)] = {'x': ox, 'y': oy, 'theta': 0}\n",
    "    \n",
    "    with open(image_paths['scan_dir'] + '/shifts.json', 'w') as f:\n",
    "        \n",
    "        json.dump(shifts, f)\n",
    "    \n",
    "    with open(image_paths['scan_dir'] + '/shifts.csv', 'w') as f:\n",
    "        \n",
    "        fields = ['pos', 'x', 'y', 'theta']\n",
    "        w = csv.DictWriter(f, fields)\n",
    "        w.writeheader()\n",
    "        \n",
    "        for k, v in sorted(shifts_csv.items()):\n",
    "            \n",
    "            row = {'pos': k}\n",
    "            row.update(v)\n",
    "            w.writerow(row)\n",
    "    return shifts, shifts_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ca8c3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_2(shifts, shifts_csv, die_offsets, die_contours, alignment_pts, image_paths, ideal_param):\n",
    "    #loop through the angle rotation of the dies and rotate and crop entire image\n",
    "    cross = cv2.imread(image_paths['cross'])\n",
    "    squares = cv2.imread(image_paths['squares'])\n",
    "    out = cv2.imread(image_paths['input'])\n",
    "    decoy = out.copy()\n",
    "    h,w = cross.shape[1], cross.shape[0]\n",
    "    scale = ideal_param['scale']\n",
    "    midpts = ideal_param['midpts']\n",
    "    x_midpoint = ideal_param['x_midpoint']\n",
    "    y_midpoint = ideal_param['y_midpoint']\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    \n",
    "    for r in range(ideal_param['num_rows']):#TODO: might need to make this dependent on keys of shifts\n",
    "        for c in range(ideal_param['num_cols']):\n",
    "            \n",
    "            \n",
    "            theta = shifts[r][c]['theta']\n",
    "            #rotate/crop template, use previously found die contours to cut die out of entire image, template match all 4 corner markers, find centers of all 4 corners\n",
    "            rot_cross = crop_rotated(cross, h, w, theta)\n",
    "            rot_squares = crop_rotated(squares, h, w, theta)\n",
    "            rot_cross = cv2.cvtColor(rot_cross, cv2.COLOR_BGR2GRAY)\n",
    "            rot_squares = cv2.cvtColor(rot_squares, cv2.COLOR_BGR2GRAY)\n",
    "            out.astype(np.uint8)\n",
    "            rot_squares.astype(np.uint8)\n",
    "            rot_cross.astype(np.uint8)\n",
    "            \n",
    "            w, h = rot_cross.shape[0], rot_cross.shape[1]\n",
    "            \n",
    "            _, _, die_w, die_h = cv2.boundingRect(die_contours[i])\n",
    "            roi = out[die_offsets[i][1]:die_offsets[i][1]+ die_h, die_offsets[i][0]:die_offsets[i][0]+ die_w]\n",
    "            roi.astype(np.uint8)\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #perform template matching on die\n",
    "            cross_pts, _ = match_template(decoy, roi, rot_cross, f\"rotated cross [{r}][{c}]\", .7)\n",
    "            squares_pts, _ = match_template(decoy, roi, rot_squares, f\"rotated squares [{r}][{c}]\", .8)\n",
    "\n",
    "            x, y = die_offsets[i][0], die_offsets[i][1]\n",
    "            # Draw a rectangle on the original image of die with no rotation\n",
    "            cv2.rectangle(out, (x, y), (x+die_w, y+die_h), (0, 255, 0), 4)  # Green rectangle, thickness 2\n",
    "            cv2.putText(out, f\"r:{r} c:{c}, i:{i} die offset\", (x - 25, y - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (240, 32, 160), 4)\n",
    "\n",
    "            #add offset from die cutout to template matched coords to get actual coords according to coord system fo entire image\n",
    "            offset_x, offset_y = die_offsets[i]\n",
    "            offset = np.array([[offset_x, offset_y]])\n",
    "            cross_pts += offset\n",
    "            squares_pts += offset\n",
    "            \n",
    "            for x,y in cross_pts:\n",
    "                cv2.circle(out, (x, y), 5, (0, 0, 255), -1)\n",
    "                cv2.putText(out, \"corner\", (x - 25, y - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                cv2.rectangle(out, (x, y), (x + w, y + h), (0, 0, 255), 5)\n",
    "            \n",
    "        \n",
    "            for x,y in squares_pts:\n",
    "                cv2.circle(out, (x, y), 5, (0, 0, 255), -1)\n",
    "                cv2.putText(out, \"corner\", (x - 25, y - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                cv2.rectangle(out, (x, y), (x + w, y + h), (0, 0, 255), 5)\n",
    "\n",
    "            #calculate centroid by adding half the width and subtracting half the height of rot_template\n",
    "            center_offset = np.array([[w//2, h//2]]) #why do we add height instead of subtract?\n",
    "            center_offset = np.repeat(center_offset, len(cross_pts), axis=0)#ensures shapes match for broadcasting adding\n",
    "            cross_pts += center_offset\n",
    "\n",
    "            center_offset2 = np.array([[w//2, h//2]]) #why do we add height instead of subtract? +y goes down \n",
    "            center_offset2 = np.repeat(center_offset2, len(squares_pts), axis=0)#ensures shapes match for broadcasting adding\n",
    "            print(\"cross_pts centers, should be 2\", len(cross_pts))\n",
    "            print(\"square_pts centers, should be 2\", len(squares_pts))\n",
    "            squares_pts += center_offset2\n",
    "\n",
    "\n",
    "            #draw centroids onto image\n",
    "            for x, y in cross_pts:\n",
    "                cv2.circle(out, (x, y), 5, (255, 0, 0), -1)\n",
    "                cv2.putText(out, \"centroid\", (x - 25, y - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            for x, y in squares_pts:\n",
    "                cv2.circle(out, (x, y), 5, (255, 0, 0), -1)\n",
    "                cv2.putText(out, \"centroid\", (x - 25, y - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            #calculate and draw center of die\n",
    "            cross_pts = np.array(cross_pts)\n",
    "            squares_pts = np.array(squares_pts)\n",
    "            pts = np.vstack((cross_pts, squares_pts))\n",
    "            die_center = np.mean(pts, axis=0)\n",
    "            ox = die_center[0]\n",
    "            oy = die_center[1] #shouldnt have a negative scale\n",
    "            shifts[r][c]['x'] =  ox\n",
    "            shifts[r][c]['y'] =  oy\n",
    "            shifts_csv[str(r) + ', ' + str(c)]['x'] =scale * ox\n",
    "            shifts_csv[str(r) + ', ' + str(c)]['y'] = - scale * oy\n",
    "            if r == 4 and c == 2:\n",
    "                cv2.circle(out, (int(ox), int(oy)), 5, (0, 255, 255), -1)#yellow = 4,2\n",
    "                cv2.putText(out, \"4,2 center of die\", (int(ox) - 25, int(oy) - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            elif r==4 and c==3:\n",
    "                cv2.circle(out, (int(ox), int(oy)), 5, (180, 105, 255), -1)#pink = 4,3\n",
    "                cv2.putText(out, \"4,3 center of die\", (int(ox) - 25, int(oy) - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.circle(out, (int(ox), int(oy)), 5, (0, 255, 0), -1)\n",
    "                cv2.putText(out, f\"{r},{c} center of die\", (int(ox) - 25, int(oy) - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "   \n",
    "            \n",
    "    for i, p in enumerate(alignment_pts):\n",
    "            shifts['alignment ' + str(i)] = {'x': p[0], 'y': p[1], 'theta': 0}\n",
    "            shifts_csv['alignment ' + str(i)] = {'x': scale * p[0], 'y': -scale * p[1], 'theta': 0}\n",
    "            \n",
    "\n",
    "            \n",
    "    \n",
    "    #sets up csv file\n",
    "    with open(image_paths['scan_dir'] + '/method2_shifts_final.csv', 'w') as f:\n",
    "        fields = ['pos', 'x', 'y', 'theta']\n",
    "        w = csv.DictWriter(f, fields)\n",
    "        w.writeheader()\n",
    "        #key,value\n",
    "        for k, v in sorted(shifts_csv.items()):\n",
    "            row = {'pos': k}\n",
    "            row.update(v)\n",
    "            w.writerow(row)\n",
    "    \n",
    "            \n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d747af0",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "81d948c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(image_paths, ideal_param, scale_to_use='detected', needs_rotation=False, has_defects=False):\n",
    "    \n",
    "    #Read image and convert to grayscale:\n",
    "    img = cv2.imread(image_paths['input'])\n",
    "    result = img.copy()\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Identify global alignment markers, adjust rotation, and rescale dimensions:\n",
    "    template_alignment = cv2.imread(image_paths['alignment'])\n",
    "    template_alignment_gray = cv2.cvtColor(template_alignment, cv2.COLOR_BGR2GRAY)\n",
    "    alignment_pts, result = match_template(result, img_gray, template_alignment_gray, \"alignment\", 0.9)\n",
    "    alignment_pts = order_alignment_marker_list(alignment_pts)\n",
    "    ideal_param['scale'], rescale = calculate_scale_using_alignment_markers(alignment_pts, ideal_param['alignment_mark_dist'])\n",
    "    ideal_param['min_die_area'] = 165000\n",
    "    ideal_param['max_die_area'] = 650000\n",
    "    img = cv2.resize(img, (int(rescale*img.shape[1]), img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    result = img.copy()\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    theta = 0 - get_angle_averaged(alignment_pts)\n",
    "    print(\"Wafer scan rotation [degrees]:\", theta)\n",
    "    \n",
    "    #Use given scale instead of calculated scale:\n",
    "    if scale_to_use == 'given':\n",
    "        \n",
    "        ideal_param['scale'] = pixel_to_um_scale_given[i]\n",
    "    \n",
    "    #If the image needs rotation, rotate and crop the image, then re-identify global alignment markers and re-calculated scale:\n",
    "    if needs_rotation:\n",
    "        \n",
    "        i = 0\n",
    "        #for i in range(ideal_param['number_of_rotation_correction']):\n",
    "        while abs(theta) > ideal_param['target_rotation']:\n",
    "\n",
    "            if i == int(ideal_param['number_of_rotation_correction']):\n",
    "                break\n",
    "            \n",
    "            h, w = img.shape[0], img.shape[1]\n",
    "            img = ndimage.rotate(img, -theta)\n",
    "            img = crop_rotated(img, h, w, -theta)\n",
    "            result = img.copy()\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            alignment_pts, result = match_template(result, img_gray, template_alignment_gray, \"alignment\", 0.9)\n",
    "            alignment_pts = order_alignment_marker_list(alignment_pts)\n",
    "            ideal_param['scale'], _ = calculate_scale_using_alignment_markers(alignment_pts, ideal_param['alignment_mark_dist'])\n",
    "            ideal_param['min_die_area'] = (0.9*ideal_param['die_width']/ideal_param['scale'])*(0.9*ideal_param['die_height']/ideal_param['scale'])\n",
    "            ideal_param['max_die_area'] = (1.1*ideal_param['die_width']/ideal_param['scale'])*(1.1*ideal_param['die_height']/ideal_param['scale'])\n",
    "            theta = 0 - get_angle_averaged(alignment_pts)\n",
    "            print(\"Wafer scan rotation [degrees]:\", theta)\n",
    "            i += 1\n",
    "\n",
    "    #Calculates midpoint of the global alignemnt markers:\n",
    "    w0, h0 = template_alignment_gray.shape[::-1]\n",
    "    \n",
    "    for i, c in enumerate(alignment_pts):\n",
    "        \n",
    "        alignment_pts[i] = np.array([c[0] + w0 // 2, c[1] + h0 // 2])\n",
    "    \n",
    "    #Use CV2 thresholding to get all contours in the image:\n",
    "    _, bw = cv2.threshold(img_gray, 232, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    cv2.imwrite('./input_images/threshold.png', bw)\n",
    "    \n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    \n",
    "    #Identify dies by searching for contours with area matching the expected die area such that min area = 0.81*die area and max area = 1.21*die area:\n",
    "    die_contours, die_offsets = identify_dies(contours, alignment_pts, min_die_area=ideal_param['min_die_area'], max_die_area=ideal_param['max_die_area'])\n",
    "\n",
    "    x_off, y_off, result = calculate_offset(alignment_pts, die_offsets, ideal_param, image_paths) \n",
    "    ideal_param['assembly_x_offset'] = -1600\n",
    "    ideal_param['assembly_y_offset'] = 2030\n",
    "\n",
    "    result = identify_misalignment(result, die_contours, die_offsets, alignment_pts, ideal_param, image_paths)\n",
    "    cv2.imwrite(\"/Users/travisha/Downloads/CHIPS_research/identifymisalign.jpg\", result)\n",
    "\n",
    "   \n",
    "    \n",
    "    # #Match templates of the die alignment markers (crosses/squares):\n",
    "    # template_cross = cv2.imread(image_paths['cross'])\n",
    "    # template_squares = cv2.imread(image_paths['squares'])\n",
    "    # template_cross_gray = cv2.cvtColor(template_cross, cv2.COLOR_BGR2GRAY)\n",
    "    # template_squares_gray = cv2.cvtColor(template_squares, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # cross_thres = .77\n",
    "    # square_thres = .789\n",
    "    # cross_pts, result = match_template(result, img_gray, template_cross_gray, \"cross\", cross_thres)\n",
    "    # squares_pts, result = match_template(result, img_gray, template_squares_gray, \"squares\", square_thres)\n",
    "    # numcross = len(cross_pts)\n",
    "    # numsqaures = len(squares_pts)\n",
    "    # while  numcross!= 50:\n",
    "    #     if(numcross < 50):\n",
    "    #         cross_thres -= .01\n",
    "    #     if(numcross > 50):\n",
    "    #         cross_thres += .01\n",
    "    #     print(\"cross thresh:\", cross_thres)\n",
    "    #     cross_pts, result = match_template(result, img_gray, template_cross_gray, \"cross\", cross_thres)\n",
    "    #     numcross = len(cross_pts)\n",
    "    # rep = 5\n",
    "    # while  numsqaures!= 50 and rep > 0:\n",
    "    #     if numsqaures < 50:\n",
    "    #         square_thres -= .002\n",
    "    #     if numsqaures > 50:\n",
    "    #         square_thres += .001\n",
    "    #     print(\"square thres:\", square_thres)\n",
    "    #     squares_pts, result = match_template(result, img_gray, template_squares_gray, \"squares\", square_thres)\n",
    "    #     numsqaures = len(squares_pts)\n",
    "    #     rep-=1\n",
    "    \n",
    "\n",
    "    \n",
    "    # #Identify the alignment markers belonging to each die and calculate die offsets based on those alignment marks:\n",
    "    # w1, h1 = template_cross_gray.shape[::-1]\n",
    "    # w2, h2 = template_squares_gray.shape[::-1]\n",
    "    # result = identify_corner_markers(result, w1//2, h1//2, w2//2, h2//2, cross_pts, squares_pts)#correctly detects all dies\n",
    "    # ideal_param['oc'] = [(w1 + w2) / 2, (h1 + h2) / 2]\n",
    "    # shifts, shifts_csv = identify_misalignment_with_corner_markers(cross_pts, squares_pts, alignment_pts, ideal_param, image_paths)\n",
    "    # method_2(shifts, shifts_csv, die_offsets, die_contours, alignment_pts, image_paths, ideal_param)\n",
    "    \n",
    "    # #Create output bitmap:\n",
    "    # cv2.imwrite(image_paths['output'], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "6a47bfbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time = 2024-09-13 12:45:23.052797\n",
      "Detected alignment markers: 4\n",
      "Pixel to um scale (w.r.t. alignment markers) [um/pixel]: 2.207990242824598\n",
      "Wafer scan rotation [degrees]: 0.08603387639409091\n",
      "Detected alignment markers: 4\n",
      "Pixel to um scale (w.r.t. alignment markers) [um/pixel]: 2.2070668458626375\n",
      "Wafer scan rotation [degrees]: 0.0012631316489668983\n",
      "UL ALIGNMENT PT [  615 11612]\n",
      "2583\n",
      "2056\n",
      "x offset -1964\n",
      "y offset 1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/q5nlgtbd0h928z1tq9v9s8440000gq/T/ipykernel_43269/3857381294.py:33: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  tl = np.int0([ideal_pts[r, c, 0], ideal_pts[r, c, 1]])\n",
      "/var/folders/vs/q5nlgtbd0h928z1tq9v9s8440000gq/T/ipykernel_43269/3857381294.py:34: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  br = np.int0([ideal_pts[r, c, 0] + die_width, ideal_pts[r, c, 1] + die_width])\n",
      "/var/folders/vs/q5nlgtbd0h928z1tq9v9s8440000gq/T/ipykernel_43269/3857381294.py:47: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Time = 2024-09-13 12:47:22.558934\n",
      "Run Time = 0:01:59.506137\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate pitch using midpoint / avg\n",
    "# average distance between top left corners of two adjacent dies: ~402 pixels <==> 1634 um\n",
    "# average h, w: ~246 pixels <==> 1000 um\n",
    "# average spacing between dies: ~156 pixels <==> 634 um\n",
    "scan_dir = '/Users/travisha/Downloads/CHIPS_research'\n",
    "image_paths = {}\n",
    "image_paths['scan_dir'] = scan_dir\n",
    "image_paths['input'] = scan_dir + '/v1_Sample2_Scan2_corrected.png'\n",
    "image_paths['output'] = scan_dir + '/output.bmp'\n",
    "image_paths['corners'] = scan_dir + '/cornersmethod2.png'\n",
    "image_paths['alignment'] = scan_dir + '/alignment_quarter.bmp'\n",
    "image_paths['cross'] = scan_dir + '/cross_quarter.bmp'\n",
    "image_paths['squares'] = scan_dir + '/squares_quarter.bmp'\n",
    "image_paths['cross_blurred'] = None\n",
    "image_paths['squares_blurred'] = None\n",
    "pixel_to_um_scale_given = None\n",
    "pixel_to_um_scale_detected = None\n",
    "ideal_param = {}\n",
    "ideal_param['num_rows'] = 5\n",
    "ideal_param['num_cols'] = 5\n",
    "ideal_param['die_width'] = 2000 #[um]\n",
    "ideal_param['die_height'] = 2000 #[um]\n",
    "ideal_param['pitch'] = 2800 #[um]\n",
    "ideal_param['alignment_mark_dist'] = 25000 #[um]\n",
    "\n",
    "ideal_param['number_of_rotation_correction'] = 1\n",
    "ideal_param['target_rotation'] = 0.0015 #[degrees]\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(\"Start Time =\", start_time)\n",
    "\n",
    "analysis(image_paths, ideal_param, scale_to_use='detected', needs_rotation=True, has_defects=False)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"End Time =\", end_time)\n",
    "run_time = end_time - start_time\n",
    "print(\"Run Time =\", run_time)\n",
    "# TODO: switched rows with columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b92233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import root\n",
    "# from math import cos\n",
    "\n",
    "# def eqn(x):\n",
    "#   return x + cos(x)\n",
    "\n",
    "# myroot = root(eqn, 0)\n",
    "\n",
    "# print(myroot.x)\n",
    "# print(myroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44e04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
